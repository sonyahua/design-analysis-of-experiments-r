---
title: "Ch. 2 Completely Randomized Esigns with One Factor"
author: "Sonya Hua"
date: "September 24, 2019"
output: html_document
---

```{r}
#install.packages("daewr")
library("daewr")
data(bread)
str(bread)
```
```{r}

# Data set:
bread
```

```{r}
# Regress on the treatment factors
mod0 <- lm(height ~ time, data= bread)
summary(mod0)
```

Interpretation would be if the bread was allowed to rise for 40 minutes, bread height would increase by 2.81 inches relative to the 35 minute rise time. If the bread was allowed to rise for 45 minutes, bread height wouldincrease by 2.87 inches relative to the 35 minute rise time.

Without an intercept, we can see the rise teams for each treatment level:

```{r}
# Regress on the treatment factors - no intercept
mod1 <- lm(height ~ time -1, data= bread)
summary(mod1)
```

For rise time of 35 minutes, mean bread height is  5.4 inches (cell mean). Let's see if this intuitively makes sense by looking at the data once again:

```{r}
library("dplyr")
bread %>% filter(time == 35)
(4.5 + 5 + 5.5 + 6.75) / 4
```

The math checks out. 

### Estimable Contrasts of Treatment Effects

Estimable contrasts can be obtained from the `fit.contrast` function in gmodels R package. This only works with factorized treatment levels which `time` is:

```{r}
#install.packages("gmodels")
library("gmodels")

# Estimate the avg. difference in the cell means for the first and second levels:
fit.contrast(mod0, "time", c(1,-1,0))
```

`fit.contrast` Computes the specified contrast(s) by re-fitting the model with the appropriate arguments. A contrast of the form c(1,0,0,-1) would compare the mean of the first group with the mean of the fourth group.

Let's contrast T2 - T3

```{r}
fit.contrast(mod0, "time", c(0,1,-1))
```

There is no significant difference between Treatment 2 and Treatment 3.

###2.4 Linear Models To Estimate ATE

```{r}
library(daewr)
mod0 <- lm(height ~ time, data = bread)
summary(mod0)
```


###2.4.5 ANOVA: Hypothesis Test of No Treatment Effects

```{r}
mod1 <- aov(height ~ time, data=bread)
summary(mod1)
```

There are significant differences among the mean risen dough heights for each rise time at alpha = 0.05

2.5 Verify Assumptions of the Linear Model

```{r}
par(mfrow=c(2,2))
plot(mod1, which=5)
plot(mod1, which=1)
plot(mod1,which=2)
plot(residuals(mod1) ~ loaf, main = "Residuals vs. Exp. Unit", font.main=1, data=bread)
abline(h=0, lty=2)
```

###2.5 Box Cox Power Transofmration for heterogeneous variance of residuals

```{r}
library(MASS)
bc <- boxcox(mod1)
lambda <- bc$x[which.max(bc$y)]
lambda
```
The value of lambda that maximizes the log likelihood (or minimizes the error sum of squares is the most optimal in the box-cox plot. 

Let's transofmrm the response variable with this lambda

```{r}
tbread <- transform(bread, theight= height^(lambda))
mod2 <- aov(theight ~ time, data=tbread)
summary(mod2)
```

Next, let's take a look again at the graphs to verify the assumptions of hte anaylsis. 

```{r}
par(mfrow=c(2,2))
plot(mod2, which=5)
plot(mod2, which=1)
plot(mod2,which=2)
plot(residuals(mod2) ~ loaf, main = "Residuals vs. Exp. Unit", font.main=1, data=bread)
abline(h=0, lty=2)
```

Variability of the rsiduals are about the same with the transformation. 

###2.6.3 Alternatives to LS Analysis

We can use weighted least squares where the weights are the reciprocal of the standard deviations

```{r}
with(bread, 
     {std <- tapply(height,time,sd)
     weights <- rep(1/std, each=4)
     mod3 <- lm(height ~ time, weights=weights, data=bread)
     anova(mod3)})  # calculates the sd of the response at each level of time
```

THe F-Test from the weights least squares is more sensitive than the unweighted least squares. 

We can also use a generalized linear model when the error distribution is not normal. THe `polr` function is used to fit the full and reduced model. By default, it uses the logistic link function and the multinomial distribution. 

Full model includes the treatment factor while the reduced model only includes the intercept. 

ANOVA displays the likelihood ratio test of the significance of the treatment factor. 

```{r}
library("daewr")
library("MASS")
modf <- polr(score ~ method, weight= count, data=teach)
modr <- polr(score ~ 1, weight=count, data=teach)
anova(modf, modr)
```

P-value is small indicating there's a significant difference between the teaching methods. 

### 2.7 Determining the number of replicates

We need to first determine what is the effect we want to detect with signfiicance that is practically meaningful or important. The the number of replicates can be determined using a power calculation

```{r}
library(daewr)
rmin <- 2 # smallest number of replicates considered
rmax <-6 # largest number of replicates considered
alpha <- rep(0.05, rmax-rmin+1)  #rep(0.05, 5)
sigma <- sqrt(2.1)
nlev <- 3
nreps <- rmin:rmax
Delta <- 3
power <- Fpower1(alpha,nlev,nreps,Delta,sigma)
power 

# Power chart

```

By using a vector argument for `nreps`, the function produces a corresponding vector of power values. Wee can see that r=5 replicates has a 73% chance of detecting a difference in cell means as large as 3.0 and with r=6, there is a 83% chance. 

####2.8.1 Preplanned Comparisons 

To determine which cell means are different, preplanned comparisons are used or contrasts.

```{r}
library(daewr)
mod4 <- aov(yield ~ treat, data=sugarbeet)
con <- matrix(c(1, -1/3, -1/3, -1/3, 0, 1, -1, 0, 0, 0, 1, -1), 4, 3)  # 4x3 matrix
L <- t(con)
rownames(L) <- c("-fertilizer effect", "-plowed vs. broadcast", "-January vs. April")
L
```

The function below prints the results
```{r}
options(digits=3)
library(gmodels)
print(fit.contrast(mod4, "treat", L))  

#treat=variable name, L = coefficient (vector or matrix specifying contrasts in general form)

```

1) Artificial fertilizers enhance yield
2) Broadcast application results in higher yields than plowed application
3) There is no significant difference in yield between April and January

```{r}
contrasts(bread$time) <- contr.poly(3)
contrasts(bread$time)
```

This shows the linear and quadratic contrasts 

Linear means if we increase the dose level the Y values will increase, and we can select the best level based on the highest dose.

Quadratic means, if we increase the dose level the Y values will be increased until certain dose after that the level of dosage will have a negative effect.

Below calculates the contrasts and displays the results


```{r}
mod3 <-aov(height ~ time, bread)
summary(lm(mod3))
```

THere is a significant linear trend for time, but no significant quadratic trend. If there levels for the factor time were created with the ordered command instead of factor command, R automatically creates the X matrix using the orthogonal polynomial contrasts and the summary table above can be created without creating additional contrasts for time. 

2.8.2 Unplanned Comparisons

When doing individual comparisons, we should make an adjustment when there's more than 2 levels. For pairwise comparisons, Tukey's HSD can be used adjusting hte cricital region by using the studentized range statstic instead of t-distribution.

```{r}
# Before tukey adjustment
mod4 <- aov(yield~ treat, data=sugarbeet)
summary(mod4)

#After tukey adjustment
mod4.tukey <- TukeyHSD(mod4, ordered=T)
mod4.tukey
```
The first column lists the comparisons.
The 2nd column lists the difference in cell means.
The next 2 columns are upper and lower bounds at 95% CI on the difference of means. 
The final column is a p-value for the test of the null hypothesis that the 2 means are equal. 

For example, the last comparison (C vs. D) includes 0 in its confidence interval - which is not significantly different than the yield for treatment. All other pairwise comparisons show a signicant


```{r}
# NK Method
#install.packages("agricolae")
library(agricolae)
#install.packages("mime")
compare <- SNK.test(mod4, "treat", alpha=0.05)
print(compare)
```

####2.8.3 Comparison of All Means to a Control or the Best level

Dunnett developed a method to compare different experimental levels  to a control while controlling the experiment-wise type 1 error rate. When using the glht function, by default the first level of the treatment factor is the control. First, look at the observed means to decide which treatment level is the best. 

```{r}
summary(sugarbeet)

library("multcomp")
sugar.dun<- glht(mod4, linfct=mcp(treat="Dunnett"), alternative="greater")
summary(sugar.dun)
```

When comparing all treatment levels to a control, the desired direction of the difference is often known. Therefore, a one-tailed test, rather than a 2-tailed test, may be required. 